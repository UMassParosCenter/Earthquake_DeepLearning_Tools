{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ee0b87-f55a-4cf5-a7ca-510df9aa60c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 1/5\n",
      "Fold 1, Epoch 1: Train Acc: 0.4097, Val Acc: 0.3767\n",
      "Fold 1, Epoch 10: Train Acc: 0.9091, Val Acc: 0.9283\n",
      "Fold 1, Epoch 20: Train Acc: 0.9304, Val Acc: 0.9417\n",
      "Fold 1, Epoch 30: Train Acc: 0.9495, Val Acc: 0.9417\n",
      "Early stopping triggered.\n",
      "\n",
      "Classification report for fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9437    0.9640    0.9537       139\n",
      "           1     0.9383    0.9048    0.9212        84\n",
      "\n",
      "    accuracy                         0.9417       223\n",
      "   macro avg     0.9410    0.9344    0.9375       223\n",
      "weighted avg     0.9416    0.9417    0.9415       223\n",
      "\n",
      "Starting Fold 2/5\n",
      "Fold 2, Epoch 1: Train Acc: 0.3805, Val Acc: 0.3767\n",
      "Fold 2, Epoch 10: Train Acc: 0.9282, Val Acc: 0.9372\n",
      "Fold 2, Epoch 20: Train Acc: 0.9439, Val Acc: 0.9417\n",
      "Early stopping triggered.\n",
      "\n",
      "Classification report for fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9200    0.9928    0.9550       139\n",
      "           1     0.9863    0.8571    0.9172        84\n",
      "\n",
      "    accuracy                         0.9417       223\n",
      "   macro avg     0.9532    0.9250    0.9361       223\n",
      "weighted avg     0.9450    0.9417    0.9408       223\n",
      "\n",
      "Starting Fold 3/5\n",
      "Fold 3, Epoch 1: Train Acc: 0.4433, Val Acc: 0.3767\n",
      "Fold 3, Epoch 10: Train Acc: 0.9080, Val Acc: 0.9372\n",
      "Fold 3, Epoch 20: Train Acc: 0.9360, Val Acc: 0.9596\n",
      "Fold 3, Epoch 30: Train Acc: 0.9484, Val Acc: 0.9596\n",
      "Early stopping triggered.\n",
      "\n",
      "Classification report for fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9580    0.9856    0.9716       139\n",
      "           1     0.9750    0.9286    0.9512        84\n",
      "\n",
      "    accuracy                         0.9641       223\n",
      "   macro avg     0.9665    0.9571    0.9614       223\n",
      "weighted avg     0.9644    0.9641    0.9639       223\n",
      "\n",
      "Starting Fold 4/5\n",
      "Fold 4, Epoch 1: Train Acc: 0.3692, Val Acc: 0.3767\n",
      "Fold 4, Epoch 10: Train Acc: 0.9270, Val Acc: 0.9283\n",
      "Fold 4, Epoch 20: Train Acc: 0.9416, Val Acc: 0.9372\n",
      "Early stopping triggered.\n",
      "\n",
      "Classification report for fold 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9437    0.9640    0.9537       139\n",
      "           1     0.9383    0.9048    0.9212        84\n",
      "\n",
      "    accuracy                         0.9417       223\n",
      "   macro avg     0.9410    0.9344    0.9375       223\n",
      "weighted avg     0.9416    0.9417    0.9415       223\n",
      "\n",
      "Starting Fold 5/5\n",
      "Fold 5, Epoch 1: Train Acc: 0.4215, Val Acc: 0.4009\n",
      "Fold 5, Epoch 10: Train Acc: 0.8946, Val Acc: 0.9640\n",
      "Fold 5, Epoch 20: Train Acc: 0.9350, Val Acc: 0.9595\n",
      "Early stopping triggered.\n",
      "\n",
      "Classification report for fold 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9767    0.9130    0.9438       138\n",
      "           1     0.8710    0.9643    0.9153        84\n",
      "\n",
      "    accuracy                         0.9324       222\n",
      "   macro avg     0.9239    0.9387    0.9295       222\n",
      "weighted avg     0.9367    0.9324    0.9330       222\n",
      "\n",
      "\n",
      "===== Final Cross-Validation Metrics =====\n",
      "Accuracy:  0.9443\n",
      "Precision: 0.9387\n",
      "Recall:    0.9119\n",
      "F1 Score:  0.9251\n",
      "ROC AUC:   0.9729\n",
      "Confusion Matrix:\n",
      "[[669  25]\n",
      " [ 37 383]]\n",
      "\n",
      "Average Train Accuracy: 0.9535 +/- 0.0058\n",
      "Average Val Accuracy:   0.9443 +/- 0.0105\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNN Training Script for Earthquake Detection Using PSD Features\n",
    "================================================================\n",
    "\n",
    "This notebook trains a convolutional neural network (CNN) to classify infrasound events \n",
    "(earthquake vs. background noise) using power spectral density (PSD) data.\n",
    "\n",
    "Key Components:\n",
    "---------------\n",
    "1. **Data Loading & Preprocessing**\n",
    "   - Loads PSD data from pickle files (earthquake and background).\n",
    "   - Extracts PSD arrays, flattens them, and applies log normalization.\n",
    "   - Saves normalization statistics (`mean.npy`, `std.npy`).\n",
    "\n",
    "2. **Dataset & Training Utilities**\n",
    "   - Custom `Dataset` class for PyTorch DataLoader.\n",
    "   - Implements early stopping to prevent overfitting.\n",
    "\n",
    "3. **Cross-Validation Training Loop**\n",
    "   - 5-fold stratified cross-validation.\n",
    "   - Applies class balancing with weighted loss.\n",
    "   - Uses RAdam optimizer and monitors validation performance.\n",
    "   - Saves model and data for each fold.\n",
    "\n",
    "4. **Evaluation**\n",
    "   - Reports standard classification metrics per fold.\n",
    "   - Computes and prints aggregate cross-validation metrics:\n",
    "     Accuracy, Precision, Recall, F1 Score, ROC AUC, and Confusion Matrix.\n",
    "\n",
    "Outputs:\n",
    "--------\n",
    "- Trained model checkpoints: `fold_v2_outputs/fold_*/CNNmodel.pth`\n",
    "- Preprocessed data: `fold_v2_outputs/fold_*/data.npz`\n",
    "- Normalization stats: `mean.npy`, `std.npy`\n",
    "\n",
    "Dependencies:\n",
    "-------------\n",
    "- torch, numpy, sklearn, torch_optimizer, tqdm\n",
    "- Custom modules: `psd_pickle_utils`, `cnn_model`\n",
    "\n",
    "Ethan Gelfand, 08/06/2025\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch_optimizer as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from psd_pickle_utils import load_pickle_data, extract_psd_array\n",
    "from cnn_model import EarthquakeCNN\n",
    "\n",
    "# -----------------------------\n",
    "# Utility Classes\n",
    "# -----------------------------\n",
    "\n",
    "class PSD_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# -----------------------------\n",
    "# Data Loading and Preprocessing\n",
    "# -----------------------------\n",
    "\n",
    "patheq = \"../DataCollection_Preprocessing/Exported_Paros_Data/PSD_Windows_Earthquake_100Hz.pkl\"\n",
    "pathbg = \"../DataCollection_Preprocessing/Exported_Paros_Data/PSD_Windows_Background_100Hz.pkl\"\n",
    "\n",
    "EarthquakeData = load_pickle_data(patheq)\n",
    "BackgroundData = load_pickle_data(pathbg)\n",
    "\n",
    "eq_array = extract_psd_array(EarthquakeData)\n",
    "bg_array = extract_psd_array(BackgroundData)\n",
    "\n",
    "eq_labels = np.ones(len(eq_array), dtype=int)\n",
    "bg_labels = np.zeros(len(bg_array), dtype=int)\n",
    "\n",
    "X = np.concatenate([eq_array, bg_array], axis=0)\n",
    "y = np.concatenate([eq_labels, bg_labels], axis=0)\n",
    "\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Shuffle\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y[indices]\n",
    "\n",
    "# Normalize\n",
    "X_log = np.log10(X + 1e-10)\n",
    "mean, std = X_log.mean(axis=0), X_log.std(axis=0) + 1e-6\n",
    "X = (X_log - mean) / std\n",
    "\n",
    "np.save(\"../DataCollection_Preprocessing/Exported_Paros_Data/mean.npy\", mean)\n",
    "np.save(\"../DataCollection_Preprocessing/Exported_Paros_Data/std.npy\", std)\n",
    "\n",
    "# -----------------------------\n",
    "# Cross-Validation Training Loop\n",
    "# -----------------------------\n",
    "\n",
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_accs, fold_val_accs = [], []\n",
    "all_val_labels, all_val_preds, all_val_probs = [], [], []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Starting Fold {fold+1}/{K}\")\n",
    "    fold_dir = f\"fold_outputs/fold_{fold+1}\"\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weights[1] *= 3.0  # Emphasize Earthquake class\n",
    "\n",
    "    train_dataset = PSD_Dataset(X_train, y_train)\n",
    "    val_dataset = PSD_Dataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = EarthquakeCNN(X.shape[1]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
    "    optimizer = optim.RAdam(model.parameters(), lr=1e-4)\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=1e-4)\n",
    "\n",
    "    for epoch in range(70):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "        train_acc = correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == targets).sum().item()\n",
    "\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Fold {fold+1}, Epoch {epoch+1}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    fold_train_accs.append(train_acc)\n",
    "    fold_val_accs.append(val_acc)\n",
    "\n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    val_preds, val_labels, val_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_preds.extend(predicted.cpu().numpy())\n",
    "            val_labels.extend(targets.cpu().numpy())\n",
    "            val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_val_labels.extend(val_labels)\n",
    "    all_val_preds.extend(val_preds)\n",
    "    all_val_probs.extend(val_probs)\n",
    "\n",
    "    np.savez(os.path.join(fold_dir, \"data.npz\"), X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "    torch.save(model.state_dict(), os.path.join(fold_dir, \"CNNmodel.pth\"))\n",
    "\n",
    "    print(f\"\\nClassification report for fold {fold+1}:\")\n",
    "    print(classification_report(val_labels, val_preds, digits=4))\n",
    "\n",
    "# -----------------------------\n",
    "# Final Metrics\n",
    "# -----------------------------\n",
    "\n",
    "print(\"\\n===== Final Cross-Validation Metrics =====\")\n",
    "print(f\"Accuracy:  {accuracy_score(all_val_labels, all_val_preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(all_val_labels, all_val_preds):.4f}\")\n",
    "print(f\"Recall:    {recall_score(all_val_labels, all_val_preds):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(all_val_labels, all_val_preds):.4f}\")\n",
    "print(f\"ROC AUC:   {roc_auc_score(all_val_labels, all_val_probs):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_val_labels, all_val_preds))\n",
    "\n",
    "print(f\"\\nAverage Train Accuracy: {np.mean(fold_train_accs):.4f} +/- {np.std(fold_train_accs):.4f}\")\n",
    "print(f\"Average Val Accuracy:   {np.mean(fold_val_accs):.4f} +/- {np.std(fold_val_accs):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2900f9-d713-4608-8eb7-876696e71658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a07fb1-2b43-46dd-8834-351f57289d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125edf8-8970-4e78-a508-ef4595302a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
